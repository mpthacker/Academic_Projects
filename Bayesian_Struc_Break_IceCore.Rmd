---
title: "Ice Core"
author: "Matt Thacker"
date: "February 27, 2018"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: inline
---
Bayesian analysis of heavy isotope (deuterium) as a function of depth in Antarctic ice core. See write up for technical details of each model and nicer looking plots. 

```{r}
library(rjags)
library(coda)

#read in data
dat<- na.omit(read.csv("Eggers_stats_no_av.csv", header=T))
#sort by depth values
dat<- dat[order(dat$depth),]
```


First we'll fit a singular breakpoint model to simulated data to ensure we've specified it well.

```{r}
#breakpoint model
breakpoint_mod <- "
model{

  ##priors
  #betas
  beta1 ~ dmnorm(b0,Vb)  	
  beta2 ~ dmnorm(b0, Vb)
  #precisions
  prec1 ~ dgamma(s1,s2)  
  prec2 ~ dgamma(s1,s2)
  #discrete uniform index for prior break point value
  K ~ dcat(pi)      

  for (i in 1:n){
    #prebreak mu process model
    mu1[i] <- beta1[1] + beta1[2]*depth[i] 
    
    #postbreak mu process model
	  mu2[i] <- beta2[1] + beta2[2]*depth[i] 
	  
	  #process model
	  mu[i] <- ifelse(i>K,mu2[i],mu1[i])      
    prec[i]<- ifelse(i>K, prec2, prec1)     
    
    # data model
    Isotope[i]  ~ dnorm(mu[i],prec[i])		
  }
}
"

##simulate 1 breakpoint data to test model
#simulated data
#x values
Xsim <- 1:200  
#breakpoints
Ksim <- 115
#betas
Bsim1 <- c(1,5)    
Bsim2<- c(3, 7)
#std. deviation
SDsim <- c(150,100)
SDsim <- c(rep(SDsim[1], Ksim),rep(SDsim[2], length(Xsim)-Ksim))


#expected y values
Yexpec <- c(Bsim1[1] + Bsim1[2]*Xsim[1:Ksim] , Bsim2[1] + Bsim2[2]*Xsim[(Ksim+1):length(Xsim)]) 
#simulated Y values
Ysim <- rnorm(200, Yexpec, SDsim) 

#plot simulated data
plot(Xsim[1:Ksim],Ysim[1:Ksim], 
     col = "red", 
     ylim = c(0, 1600), 
     xlim = c(0,200), 
     ylab = "Ysim",
     xlab = "xsim"
     )
points(Xsim[(Ksim+1):length(Xsim)], Ysim[(Ksim+1):length(Ysim)], col = "blue")

#define data list
data.sim<- list(Isotope = Ysim, depth = Xsim, n = length(Xsim))  

##priors
# regression beta means
data.sim$b0 <- as.vector(c(0,0))      
# regression beta precisions
data.sim$Vb <- solve(diag(10000,2))   
#uninformative error priors
data.sim$s1 <- .001      
data.sim$s2 <- .001   
#prior probs for discrete uniform
data.sim$pi <- rep(1/length(Xsim), length(Xsim))  

#initial conditions
nchain = 3
inits.sim <- list()
for(i in 1:nchain){
 inits.sim[[i]] <- list(beta1 = rnorm(2,0,5), beta2 = rnorm(2,0,5), prec1 = runif(1,1/100,1/20), prec2 = runif(1,1/100,1/20), K = sample(1:length(Xsim), 1))
}


##initialize and sample from model
#jags object
singleBP.sim   <- jags.model(file = textConnection(breakpoint_mod),
                             data = data.sim,
                             inits = inits.sim,
                             n.chains = nchain)
#sample from model
singleBP.sim.out<- coda.samples (model = singleBP.sim,
                            variable.names = c("K", "beta1", "beta2", "prec1", "prec2"),
                                n.iter = 100000)

#check for convergence
gelman.diag(singleBP.sim.out)

#burnin
burnin <- 40000
singleBP.sim.burn <- window(singleBP.sim.out, start = burnin)

#plot outputs 
#deal with graphics issue
par(mar=c(1,1,1,1))
plot(singleBP.sim.burn)
summary(singleBP.sim.burn)

```

Next we'll do the same with our two breakpoint model.

```{r}
##two breakpoint model
breakpoint2_mod <- "
model{

  ##priors
  #betas
  for (i in 1:3){
    beta[i,1:2] ~ dmnorm(b0,Vb)
  }
  
  #precisions
  for (i in 1:3){
    prec[i] ~ dgamma(s1,s2)
  }

  #index for prior break point value
  for (i in 1:2){
    k0[i] ~ dcat(pi)
  }  
  K[1:2] <- sort(k0)
  
  ##loop through each observation
  for (i in 1:Nobs){
    
    #calc mu at each set of betas for depth i
    for (j in 1:3){
      mu[i,j] <- beta[j,1] + beta[j,2]*depth[i]
    }
    
    ##produce final process models
    Ex_int[i] <- ifelse(i>K[1], mu[i,2], mu[i,1])
    Ex[i] <- ifelse(i>K[2], mu[i,3], Ex_int[i])
    
    
    #same with precision
    prec_int[i]<- ifelse(i>K[1], prec[2], prec[1])
    prec_ex[i] <- ifelse(i>K[2], prec[3], prec_int[i])  #final process model output

    # data model
    Isotope[i]  ~ dnorm(Ex[i],prec_ex[i])		
  }
}
"

##simulate 2 breakpoint data to test model
#simulated data
#x values
Xsim <- 1:200 
#breakpoints
Ksim1 <- 65
Ksim2 <- 140
#betas
Bsim1 <- c(1,5)    
Bsim2<- c(0, 7)
Bsim3<- c(2,3)
#std. deviation
SDsim <- c(100,200,150) 
SDsim <- c(rep(SDsim[1], Ksim1), rep(SDsim[2], Ksim2-Ksim1), rep(SDsim[3], length(Xsim)-Ksim2))


#expected y values
Yexpec <- c(Bsim1[1] + Bsim1[2]*Xsim[1:Ksim1] , Bsim2[1] + Bsim2[2]*Xsim[(Ksim1+1):Ksim2], Bsim3[1] + Bsim3[2]*Xsim[(Ksim2+1):length(Xsim)])    
#simulated Y values
Ysim <- rnorm(length(Xsim), Yexpec, SDsim) 

#plot simulated data
plot(Xsim[1:Ksim1],Ysim[1:Ksim1], 
     col = "red", 
     ylim = c(0, 1200), 
     xlim = c(0,200), 
     ylab = "Ysim",
     xlab = "xsim"
     )
points(Xsim[(Ksim1+1):Ksim2], Ysim[(Ksim1+1):Ksim2], col = "blue")
points(Xsim[(Ksim2+1):length(Xsim)], Ysim[(Ksim2+1):length(Xsim)], col = "green")


#define data list
data.sim<- list(Isotope = Ysim, depth = Xsim, Nobs = length(Xsim))  

##prior params
# regression beta means
data.sim$b0 <- as.vector(c(0,0))      
# regression beta precisions
data.sim$Vb <- solve(diag(1000,2))  
#uninformative error priors
data.sim$s1 <- .001      
data.sim$s2 <- .001 
#prior probs for discrete uniform
data.sim$pi <- rep(1/length(Xsim), length(Xsim))  

#initial conditions
nchain = 3

#sample initial beta vals
beta.init <- list()

for (i in 1:nchain){
  beta.mat <- matrix(nrow=3,ncol=2)
  
  for (j in 1:3){
    beta.mat[j,] <- rnorm(2,0,5)
  }
  beta.init[[i]] <- beta.mat
}


#sample initial prec vals
prec.init <- list()

for (i in 1:nchain){
  prec.mat <- rep(NA, 3)
  
  for (j in 1:3){
    prec.mat[j] <- runif(1,1/1000,1/100)
  }
  
  prec.init[[i]] <- prec.mat
}
  

inits.bp2.sim <- list()
for(i in 1:nchain){
 inits.bp2.sim[[i]] <- list(
   beta = beta.init[[i]], 
   prec = prec.init[[i]], k0 = sort(sample(1:length(Xsim), 2)))
}

##initialize and sample from model
#jags object
twoBP.sim   <- jags.model(file = textConnection(breakpoint2_mod),
                             data = data.sim,
                             inits = inits.bp2.sim,
                             n.chains = nchain)
#sample from model
twoBP.sim.out2<- coda.samples (model = twoBP.sim,
                            variable.names = c("K", "beta", "prec"),
                                n.iter = 100000)

#check for convergence
gelman.diag(twoBP.sim.out2)

#burn
burnin <- 40000
twoBP.sim.burn <- window(twoBP.sim.out2, start = burnin)

#outputs
par(mar=c(1,1,1,1))
plot(twoBP.sim.burn)
summary(twoBP.sim.burn)

```


Now lets fit our one breakpoint model to the ice core data
```{r}
#define data list
data.bp<- list(Isotope = dat$deuturium, depth = dat$depth, n = nrow(dat))  

##priors
# regression beta means
data.bp$b0 <- as.vector(c(0,0))      
# regression beta precisions
data.bp$Vb <- solve(diag(10000,2))   
# uninformative error prior
data.bp$s1 <- .1      
data.bp$s2 <- .1   
#prior probs for discrete uniform
data.bp$pi <- rep(1/nrow(dat), nrow(dat))  

#initial conditions
nchain = 3
inits.bp <- list()
for(i in 1:nchain){   #set different values for each chain
 inits.bp[[i]] <- list(beta1 = rnorm(2,0,5), beta2 = rnorm(2,0,5), prec1 = runif(1,1/1000,1/100), prec2 = runif(1,1/1000,1/100), K = sample(1:nrow(dat), 1))
}

#estimate model and sample from it
bp.model   <- jags.model(file = textConnection(breakpoint_mod),
                             data = data.bp,
                             inits = inits.bp,
                             n.chains = nchain)
bp.out<- coda.samples (model = bp.model,
                            variable.names = c("K", "beta1", "beta2", "prec1","prec2"),
                                n.iter = 100000)

#convergence?
gelman.diag(bp.out)


#burnin
burnin <- 40000
bp.burn <- window(bp.out, start=burnin)

#outputs
summary(bp.burn)
effectiveSize(bp.burn)
gelman.diag(bp.burn)

##predictive and credible intervals
#define variables and empty storage
bp.mat <- as.matrix(bp.burn)
#number of samples for generating intervals
nsamp <- 10000          
#sample row indices 
samp <- sample.int(nrow(bp.mat),nsamp)    
#x values to predict over
xpred <- dat$depth      
#number of predictions to make
npred <- length(xpred)

##storage for vals
# storage for predictive interval
prebreak.ypred <- matrix(NA,nrow=nsamp,ncol=npred)  
postbreak.ypred <- matrix(NA,nrow=nsamp,ncol=npred)
#storage for credible interval
prebreak.ycred <- matrix(NA,nrow=nsamp,ncol=npred)
postbreak.ycred <- matrix(NA,nrow=nsamp,ncol=npred)

#loop through to calculate intervals
for(g in seq_len(nsamp)){
  #sample from parameters by row
  theta = bp.mat[samp[g],]  
  
  #loop through each row by column in ycred and ypred 
  for (j in 1:npred){       
    #post breakpoint model
    if (j > theta["K"]){    
      postbreak.ycred[g,j] <- theta["beta2[1]"] + theta["beta2[2]"]*xpred[j]
      postbreak.ypred[g,j] <- rnorm(1,postbreak.ycred[g,j],1/sqrt(theta["prec2"]))
    } else {                #pre breakpoint model
      prebreak.ycred[g,j] <- theta["beta1[1]"] + theta["beta1[2]"]*xpred[j]
      prebreak.ypred[g,j] <- rnorm(1,prebreak.ycred[g,j],1/sqrt(theta["prec1"]))
    }
  }
}

#create 1 ycred and ypred matrix
ycred <- matrix(NA,nrow=nsamp,ncol=npred)
ypred <- matrix(NA,nrow=nsamp,ncol=npred)

#loop through and combine pre and post break values
for (i in 1:nsamp){     
  ycred[i,] <- na.omit(c(prebreak.ycred[i,], postbreak.ycred[i,]))
  ypred[i,] <- na.omit(c(prebreak.ypred[i,], postbreak.ypred[i,]))
}

##calc intervals
# credible interval and median
ci.bp <- apply(ycred,2,quantile,c(0.025,0.5,0.975))  
# prediction interval
pi.bp <- apply(ypred,2,quantile,c(0.025,0.975))        
#plot em
plot(dat$depth, dat$deuturium, ylim= c(-280, -200))
lines(xpred, ci.bp[2,], type="l", col = 1, lwd= 2)  #median model
lines(xpred, ci.bp[1,], type="l", lty = 2, col = "red", lwd = 2)  #CI
lines(xpred, ci.bp[3,], type="l", lty = 2, col = "red", lwd = 2)
lines(xpred, pi.bp[1,], type="l", lty = 4, col = "blue", lwd = 2)   #PI
lines(xpred, pi.bp[2,], type="l", lty = 4, col = "blue", lwd = 2)


```

Next we'll try fitting a model for two breakpoints which will fail to converge on values for K, or converge to a value for K[2] which is the final index available. In either case the data do no support the adoption of this model.

```{r}

#define data list
data.bp2<- list(Isotope = dat$deuturium, depth = dat$depth, Nobs = nrow(dat))  

##priors
# regression beta means
data.bp2$b0 <- as.vector(c(0,0))      
# regression beta precisions
data.bp2$Vb <- solve(diag(10000,2))  
# uninformative error prior
data.bp2$s1 <- .01      
data.bp2$s2 <- .01   
#prior probs for discrete uniform
data.bp2$pi <- rep(1/nrow(dat), nrow(dat))  


#initial conditions
nchain = 3

#sample initial beta vals
beta.init <- list()

for (i in 1:nchain){
  beta.mat <- matrix(nrow=3,ncol=2)
  
  for (j in 1:3){
    beta.mat[j,] <- rnorm(2,0,5)
  }
  beta.init[[i]] <- beta.mat
}


#sample initial prec vals
prec.init <- list()

for (i in 1:nchain){
  prec.mat <- rep(NA, 3)
  
  for (j in 1:3){
    prec.mat[j] <- runif(1,1/1000,1/100)
  }
  
  prec.init[[i]] <- prec.mat
}
  

inits.bp2 <- list()
for(i in 1:nchain){
 inits.bp2[[i]] <- list(
   beta = beta.init[[i]], 
   prec = prec.init[[i]], k0 = sort(sample(1:length(Xsim), 2)))
}

##initialize model sample from it
#jags object
bp2.model   <- jags.model(file = textConnection(breakpoint2_mod),
                             data = data.bp2,
                             inits = inits.bp2,
                             n.chains = nchain)
#sample from model
bp2.out<- coda.samples (model = bp2.model,
                            variable.names = c("K", "beta", "prec"),
                                n.iter = 250000)

#convergence?
gelman.diag(bp2.out)

#burnin
burnin <- 150000
bp2.burn <- window(bp2.out, start=burnin)

#check for convergence
par(mar=c(1,1,1,1))
gelman.diag(bp2.burn)
plot(bp2.burn)
```


Now lets fit our polynomial regression models starting with quadratic (2nd order)

```{r}
#bayesian fitting of polynomial (2nd order) regression (linear with respect to parameters)
quad_regression<- "
model{

  ##priors
  #betas
  beta ~ dmnorm(b0,Vb)  
  #precision
  prec ~ dgamma(s1,s2)  

  ##process and data model
  for(i in 1:n){
    # process model
	  mu[i] <- beta[1] + beta[2]*x[i,1] + beta[3]*x[i,2]  	
	  # data model
	  Isotope[i]  ~ dnorm(mu[i],prec)		
  }
}
"

##fit model
#specify data values
data.quad<- list(Isotope = dat$deuturium, x = cbind(dat$depth, dat$depth^2), n = nrow(dat))  

##priors
# regression beta means
data.quad$b0 <- as.vector(c(0,0,0))   
# regression beta precisions
data.quad$Vb <- solve(diag(10000,3))   
# uninformative error priors
data.quad$s1 <- .1      
data.quad$s2 <- .1  

#initial conditions
inits.quad<- list()
for (i in 1:nchain){
  inits.quad[[i]]<- list(beta = rnorm(3,0,5), prec = runif(1,1/1000,1/100))
}

##estimate and sample from model
#JAGS object
quad.model   <- jags.model(file = textConnection(quad_regression),
                             data = data.quad,
                             inits = inits.quad,
                             n.chains = nchain)
#sample from model
quad.out<- coda.samples (model = quad.model,
                            variable.names = c("beta", "prec"),
                                n.iter = 5000)

#calc DIC for future model selection
quad.DIC<- dic.samples(model = quad.model, n.iter = 5000) 


#burnin
burnin <- 1000
quad.burn <- window(quad.out, start = burnin)

#outputs
summary(quad.burn)
par(mar=c(1,1,1,1))
plot(quad.burn)
gelman.diag(quad.burn)


##predictive and credible intervals
#initial values
quad.mat <- as.matrix(quad.burn)
nsamp <- 10000
samp <- sample.int(nrow(quad.mat),nsamp)
xpred <- dat$depth
npred <- length(xpred)          
ycred <- matrix(NA,nrow=nsamp,ncol=npred)
ypred <- matrix(NA,nrow=nsamp,ncol=npred)

##calculate interval values
#loop through and fill each row
for(g in seq_len(nsamp)){   
  #sampled parameters
  theta = quad.mat[samp[g],]   
  
  #credible interval
  ycred[g,] <- theta["beta[1]"] + theta["beta[2]"]*xpred + theta["beta[3]"]*xpred^2
  
  #predictive interval
  ypred[g,] <- rnorm(npred,ycred[g,],1/sqrt(theta["prec"]))
}

##intervals themselves
# credible interval and median
ci.quad <- apply(ycred,2,quantile,c(0.025,0.5,0.975))  
# prediction interval
pi.quad <- apply(ypred,2,quantile,c(0.025,0.975))   

#plot it
plot(dat$depth, dat$deuturium, ylim= c(-280, -200))
lines(xpred, ci.quad[2,], type="l", col = 1, lwd= 2)    #median model
lines(xpred, ci.quad[1,], type="l", lty = 2, col = "red", lwd = 2)  #CI
lines(xpred, ci.quad[3,], type="l", lty = 2, col = "red", lwd = 2)
lines(xpred, pi.quad[1,], type="l", lty = 2, col = "blue", lwd = 2) #PI
lines(xpred, pi.quad[2,], type="l", lty = 2, col = "blue", lwd = 2)


```


Now lets fit a cubic (3rd order regression)

```{r}
#bayesian fitting of polynomial (3rd order) regression (linear with respect to parameters)
cubic_regression<- "
model{

  ##priors
  #betas
  beta ~ dmnorm(b0,Vb)  
  #precision
  prec ~ dgamma(s1,s2)  

  ##process and data model
  for(i in 1:n){
    # process model
	  mu[i] <- beta[1] + beta[2]*x[i,1] + beta[3]*x[i,2] + beta[4]*x[i,3] 	
	  # data model
	  Isotope[i]  ~ dnorm(mu[i],prec)		
  }
}
"

#specify data values
data.cubic<- list(Isotope = dat$deuturium, x = cbind(dat$depth, dat$depth^2, dat$depth^3), n = nrow(dat))  

##priors
# regression beta means
data.cubic$b0 <- as.vector(c(0,0,0,0))  
# regression beta precisions
data.cubic$Vb <- solve(diag(10000,4))  
# uninformative error priors
data.cubic$s1 <- .1      
data.cubic$s2 <- .1

#initial conditions
inits.cubic<- list()
for (i in 1:nchain){
  inits.cubic[[i]]<- list(beta = rnorm(4,0,5), prec = runif(1,1/1000,1/100))
}

#estimate from and sample model
cubic.model   <- jags.model(file = textConnection(cubic_regression),
                             data = data.cubic,
                             inits = inits.cubic,
                             n.chains = nchain)
cubic.out<- coda.samples (model = cubic.model,
                            variable.names = c("beta", "prec"), n.iter = 5000)
cubic.DIC<- dic.samples(model = cubic.model, n.iter = 5000)


#burnin
burnin <- 1000
cubic.burn <- window(cubic.out, start = burnin)

#outputs
summary(cubic.burn)
effectiveSize(cubic.burn)
gelman.diag(cubic.burn)

#predictive and credible intervals
#initial values
cubic.mat <- as.matrix(cubic.burn)
nsamp <- 10000
samp <- sample.int(nrow(cubic.mat),nsamp)
xpred <- dat$depth
npred <- length(xpred)            
ycred <- matrix(NA,nrow=nsamp,ncol=npred)
ypred <- matrix(NA,nrow=nsamp,ncol=npred)

#calculate intervals
for(g in seq_len(nsamp)){
  theta = cubic.mat[samp[g],]
  ycred[g,] <- theta["beta[1]"] + theta["beta[2]"]*xpred + theta["beta[3]"]*xpred^2 + theta["beta[4]"]*xpred^3
  ypred[g,] <- rnorm(npred,ycred[g,],1/sqrt(theta["prec"]))
}
ci.cubic <- apply(ycred,2,quantile,c(0.025,0.5,0.975))  ## credible interval and median
pi.cubic <- apply(ypred,2,quantile,c(0.025,0.975))        ## prediction interval

#plot it
plot(dat$depth, dat$deuturium, ylim= c(-280, -200))
lines(xpred, ci.cubic[2,], type="l", col = "red", lwd= 2) #median model
lines(xpred, ci.cubic[1,], type="l", lty = 2, col = "red", lwd = 2)   #CI
lines(xpred, ci.cubic[3,], type="l", lty = 2, col = "red", lwd = 2)
lines(xpred, pi.cubic[1,], type="l", lty = 2, col = "blue", lwd = 2)  #PI
lines(xpred, pi.cubic[2,], type="l", lty = 2, col = "blue", lwd = 2)


```

And a quartic. JAGS crashes when trying to sample this model, the MCMC has been hardcoded in the next chunk
```{r}
##quad reg model
quartic_regression<- "
model{

  #priors
  beta ~ dmnorm(b0,Vb)  	## prior regression params
  prec ~ dgamma(s1,s2)  ## prior precision

  #process and data model
  for(i in 1:n){
	  mu[i] <- beta[1] + beta[2]*x[i,1] + beta[3]*x[i,2] + beta[4]*x[i,3] +beta[5]*x[i,4]	## process model
	  Isotope[i]  ~ dnorm(mu[i],prec)		## data model
  }


}
"

#specify data values
data.quartic<- list(Isotope = dat$deuturium, x = cbind(dat$depth, dat$depth^2, dat$depth^3, dat$depth^4), n = nrow(dat))  

##priors
# regression beta means
data.quartic$b0 <- as.vector(c(0,0,0,0,0))  
# regression beta precisions
data.quartic$Vb <- solve(diag(10000,5))   

#uninformative error prior
data.quartic$s1 <- .1      
data.quartic$s2 <- .1  

#initial conditions
inits.quartic<- list()
for (i in 1:nchain){
  inits.quartic[[i]]<- list(beta = rnorm(5,0,5), prec = runif(1,1/1000,1/100))
}

##fit and sample from model
#jags object
quartic.model   <- jags.model(file = textConnection(quartic_regression),
                             data = data.quartic,
                             inits = inits.quartic,
                             n.chains = nchain)
#sample from model will crash JAGS
#quartic.out<- coda.samples (model = quartic.model, variable.names = c("beta", "prec"), n.iter = 5000)
```

Now lets do the MCMC the hard way... Beta[5] appears to be non identifiable
```{r}
##manual sampling of quartic reg 
#define data
x<- cbind(rep(1,nrow(dat)),dat$depth, dat$depth^2, dat$depth^3, dat$depth^4)
y<- dat$deuturium

## specify priors
#number of itterations
n.g<- 50000   
#prior on the mean
bprior <- as.vector(c(0,0,0,0,0))
#inverse of prior variance 
vinvert <- solve(diag(1000,5))  
#inverse gamma prior on variance so 1/s1 from the precision prior
s1 <- 10  
s2 <- 10
n <- nrow(dat)  #sample size, should this be my sample or prior sample size? right now its sample

##precompute frequently used quantities
XX <- t(x) %*% x
XY <- t(x) %*% y
VbB <- vinvert %*% bprior

##load libraries
library(coda)
library(mvtnorm)

## Gibbs loop
gibbs_loop<- function(itt){
  ## initial conditions
  sg <- 50
  sinv <- 1/sg
  
  #mcmc storage
  ngibbs<- length(itt)
  bgibbs <- matrix(0.0,nrow=ngibbs,ncol=5)    ## storage for beta
  sgibbs <- numeric(ngibbs)           ## storage for sigma2
  dgibbs <- numeric(ngibbs)         ## storage for deviance at each itteration
  
  for(g in itt){

  ## sample regression parameters
  bigV    <- solve(sinv*XX + vinvert, tol=1e-25)  ## Covariance matrix
  littlev <- sinv*XY + VbB
  b = t(rmvnorm(1,bigV %*% littlev,bigV))   ## Vv is the mean vector

  ## sample variance
  u1 <- s1 + n/2
  u2 <- s2 + 0.5*crossprod(y-x%*%b)
  sinv <- rgamma(1,u1,u2)
  sg <- 1/sinv

  ## storage
  bgibbs[g,] <- b  ## store the current value of beta vector
  sgibbs[g]  <- sg  ## store the current value of the variance
  
  ##deviance
  l_lik <- sum(dnorm(y, x%*%b, sg*1, log=T))   #log liklihood
  dgibbs[g] <- -2*l_lik                   #deviance

  
  }
  
  #create mcmc outputs
  allgibbs<- cbind(bgibbs,sgibbs)
  colnames(allgibbs)<- c("beta1", "beta2", "beta3", "beta4", "beta5", "Variance")
  all_mcmc<- mcmc(allgibbs)
  
  return(list(all_mcmc, dgibbs))
  
}

#run mcmc, extract outputs and deviance
gibbs_list<- lapply(list(1:n.g, 1:n.g, 1:n.g), gibbs_loop)   #run three chains
gibbs_mcmc <- mcmc.list(list(gibbs_list[[1]][[1]], gibbs_list[[2]][[1]], gibbs_list[[3]][[1]]))    #mcmc outputs
gibbs_dev <- list(gibbs_list[[1]][[2]], gibbs_list[[2]][[2]], gibbs_list[[3]][[2]])     #deviance vectors

#calculate DIC
gibbs_sum<- summary(gibbs_mcmc)
beta_bar<- gibbs_sum$statistics[1:5,1]    #mean beta
var_bar<- gibbs_sum$statistics[6,1]       #mean variance
D_thetabar <- -2*sum(dnorm(y, x%*%beta_bar, var_bar*1, log=T))
Dtheta_bar <- mean(c(gibbs_dev[[1]], gibbs_dev[[2]], gibbs_dev[[3]]))
quartic.DIC <- 2*Dtheta_bar - D_thetabar

#outputs
par(mar=c(1,1,1,1))
plot(gibbs_mcmc)
effectiveSize(gibbs_mcmc)
gelman.diag(gibbs_mcmc)


#compare DICs
#quad.DIC
#cubic.DIC
quartic.DIC
```


lets compare the predictive intervals between best quad and best BP
```{r}
#plot to compare model intervals between quad and breakpoint
plot(dat$depth, dat$deuturium, ylim=c(-280, -200))
lines(xpred, ci.quad[2,], type="l", col = "red", lwd= 2)
lines(xpred, pi.quad[1,], type="l", lty = 2, col = "red", lwd = 2)
lines(xpred, pi.quad[2,], type="l", lty = 2, col = "red", lwd = 2)
lines(xpred, ci.bp[2,], type="l", col = "blue", lwd= 2)  #median model
lines(xpred, pi.bp[1,], type="l", lty = 2, col = "blue", lwd = 2)   #PI
lines(xpred, pi.bp[2,], type="l", lty = 2, col = "blue", lwd = 2)


#hahahahahaha looks like shit with too many lines
```

